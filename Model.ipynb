{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: torch.Size([3000, 20083])\n",
      "train_y shape: torch.Size([3000])\n",
      "test_x shape: torch.Size([4398, 20083])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "data = np.load('./dataset/preprocessed.npz')\n",
    "train_x = torch.from_numpy(data['train_x']).float()\n",
    "train_y = torch.from_numpy(data['train_y']).float()\n",
    "test_x = torch.from_numpy(data['test_x']).float()\n",
    "\n",
    "train_len = int(len(train_x) * 0.8)\n",
    "eval_len = len(train_x) - train_len\n",
    "train_data, eval_data = torch.utils.data.random_split(\n",
    "    torch.utils.data.TensorDataset(train_x, train_y),\n",
    "    [train_len, eval_len]\n",
    ")\n",
    "test_data = torch.utils.data.TensorDataset(test_x)\n",
    "\n",
    "print('train_x shape:', train_x.shape)\n",
    "print('train_y shape:', train_y.shape)\n",
    "print('test_x shape:', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features=20082, out_features=8192),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=8192, out_features=4096),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=2048),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2048, out_features=1024),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=128, out_features=1),\n",
    "            nn.ReLU() # force output to be >= -1 (avoid log(-ve) = nan)\n",
    "        )\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, in_data):\n",
    "        in_data[torch.isnan(in_data)] = 0 # set nan to 0\n",
    "        pred = self.net(in_data[:,1:]) # skip id\n",
    "        return pred\n",
    "\n",
    "    def loss(self, pred, truth):\n",
    "        loss = torch.sqrt(self.loss_func(torch.log1p(pred), torch.log1p(truth))) #RMSLE\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, loaders, optimizer, writer, num_epoch=10, device='cpu'):\n",
    "    def run_epoch(mode):\n",
    "        epoch_loss = 0.0\n",
    "        for i, batch in enumerate(loaders[mode], 0):\n",
    "            in_data, truth = batch\n",
    "            in_data, truth = in_data.to(device), truth.to(device)\n",
    "\n",
    "            if mode == 'train':\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            pred = model(in_data)\n",
    "            batch_loss = model.loss(pred, truth)\n",
    "            \n",
    "\n",
    "            epoch_loss += batch_loss.item()\n",
    "            if mode == 'train':\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # sum of all batchs / num of batches\n",
    "        epoch_loss /= i + 1\n",
    "        print('epoch %d %s loss %.4f' % (epoch, mode, epoch_loss))\n",
    "        # log to tensorboard\n",
    "        if not (writer is None):\n",
    "            writer.add_scalars('%s_loss' % model.__class__.__name__,\n",
    "                         tag_scalar_dict={mode: epoch_loss}, \n",
    "                         global_step=epoch)\n",
    "    for epoch in range(num_epoch):\n",
    "        run_epoch('train')\n",
    "        run_epoch('eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss 6.3843\n",
      "epoch 0 eval loss 5.5011\n",
      "epoch 1 train loss 4.4578\n",
      "epoch 1 eval loss 3.3873\n",
      "epoch 2 train loss 3.4393\n",
      "epoch 2 eval loss 3.2755\n",
      "epoch 3 train loss 3.3895\n",
      "epoch 3 eval loss 3.1915\n",
      "epoch 4 train loss 3.3728\n",
      "epoch 4 eval loss 3.2125\n",
      "epoch 5 train loss 3.4092\n",
      "epoch 5 eval loss 3.2392\n",
      "epoch 6 train loss 3.4098\n",
      "epoch 6 eval loss 3.2052\n",
      "epoch 7 train loss 3.3938\n",
      "epoch 7 eval loss 3.2373\n",
      "epoch 8 train loss 3.3741\n",
      "epoch 8 eval loss 3.1222\n",
      "epoch 9 train loss 3.3654\n",
      "epoch 9 eval loss 3.2411\n",
      "epoch 10 train loss 3.3680\n",
      "epoch 10 eval loss 3.2293\n",
      "epoch 11 train loss 3.3572\n",
      "epoch 11 eval loss 3.1412\n",
      "epoch 12 train loss 3.3753\n",
      "epoch 12 eval loss 3.1676\n",
      "epoch 13 train loss 3.3480\n",
      "epoch 13 eval loss 3.1839\n",
      "epoch 14 train loss 3.3621\n",
      "epoch 14 eval loss 3.2410\n",
      "epoch 15 train loss 3.3527\n",
      "epoch 15 eval loss 3.1859\n",
      "epoch 16 train loss 3.3490\n",
      "epoch 16 eval loss 3.1697\n",
      "epoch 17 train loss 3.3486\n",
      "epoch 17 eval loss 3.2273\n",
      "epoch 18 train loss 3.3637\n",
      "epoch 18 eval loss 3.1661\n",
      "epoch 19 train loss 3.3688\n",
      "epoch 19 eval loss 3.1350\n",
      "epoch 20 train loss 3.3702\n",
      "epoch 20 eval loss 3.2046\n",
      "epoch 21 train loss 3.3477\n",
      "epoch 21 eval loss 3.2164\n",
      "epoch 22 train loss 3.3553\n",
      "epoch 22 eval loss 3.1908\n",
      "epoch 23 train loss 3.3592\n",
      "epoch 23 eval loss 3.1739\n",
      "epoch 24 train loss 3.3513\n",
      "epoch 24 eval loss 3.1975\n",
      "epoch 25 train loss 3.3394\n",
      "epoch 25 eval loss 3.1912\n",
      "epoch 26 train loss 3.3638\n",
      "epoch 26 eval loss 3.1936\n",
      "epoch 27 train loss 3.3584\n",
      "epoch 27 eval loss 3.2329\n",
      "epoch 28 train loss 3.3608\n",
      "epoch 28 eval loss 3.1634\n",
      "epoch 29 train loss 3.3313\n",
      "epoch 29 eval loss 3.2373\n",
      "epoch 30 train loss 3.3705\n",
      "epoch 30 eval loss 3.2299\n",
      "epoch 31 train loss 3.3474\n",
      "epoch 31 eval loss 3.2082\n",
      "epoch 32 train loss 3.3504\n",
      "epoch 32 eval loss 3.1582\n",
      "epoch 33 train loss 3.3638\n",
      "epoch 33 eval loss 3.2566\n",
      "epoch 34 train loss 3.3682\n",
      "epoch 34 eval loss 3.2864\n",
      "epoch 35 train loss 3.3757\n",
      "epoch 35 eval loss 3.1730\n",
      "epoch 36 train loss 3.3579\n",
      "epoch 36 eval loss 3.1953\n",
      "epoch 37 train loss 3.3688\n",
      "epoch 37 eval loss 3.2410\n",
      "epoch 38 train loss 3.3714\n",
      "epoch 38 eval loss 3.2408\n",
      "epoch 39 train loss 3.3715\n",
      "epoch 39 eval loss 3.1520\n"
     ]
    }
   ],
   "source": [
    "model = Model().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, betas=(0.99, 0.999))\n",
    "run(\n",
    "    model=model,\n",
    "    loaders={\n",
    "        'train': torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True),\n",
    "        'eval': torch.utils.data.DataLoader(eval_data, batch_size=64, shuffle=True)\n",
    "    },\n",
    "    optimizer=optimizer, \n",
    "    writer=SummaryWriter('./logs/'), \n",
    "    num_epoch=40, \n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved\n"
     ]
    }
   ],
   "source": [
    "test_pred_tensor = model(test_x.to('cuda'))\n",
    "test_pred = test_pred_tensor.detach().cpu().numpy()\n",
    "output = np.concatenate((np.expand_dims(data['test_x'][:,0], axis=1), test_pred), axis=1)\n",
    "np.savetxt('./test_out.csv', output, header='id,revenue', delimiter=',', fmt='%i', comments='')\n",
    "print('file saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
