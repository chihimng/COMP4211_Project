{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward NN Model\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: torch.Size([3000, 20083])\n",
      "train_y shape: torch.Size([3000])\n",
      "test_x shape: torch.Size([4398, 20083])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "data = np.load('./dataset/preprocessed.npz')\n",
    "train_x = torch.from_numpy(data['train_x']).float()\n",
    "train_y = torch.from_numpy(data['train_y']).float()\n",
    "test_x = torch.from_numpy(data['test_x']).float()\n",
    "\n",
    "train_len = int(len(train_x) * 0.8)\n",
    "eval_len = len(train_x) - train_len\n",
    "whole_train_data = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "train_data, eval_data = torch.utils.data.random_split(whole_train_data, [train_len, eval_len])\n",
    "test_data = torch.utils.data.TensorDataset(test_x)\n",
    "\n",
    "print('train_x shape:', train_x.shape)\n",
    "print('train_y shape:', train_y.shape)\n",
    "print('test_x shape:', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features=20082, out_features=8192),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=8192, out_features=4096),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=2048),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2048, out_features=1024),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=1024, out_features=1),\n",
    "            nn.SELU()\n",
    "        )\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, in_data):\n",
    "        in_data[torch.isnan(in_data)] = 0 # set nan to 0\n",
    "        pred = self.net(in_data[:,1:]) # skip id\n",
    "        return pred\n",
    "\n",
    "    def loss(self, pred, truth):\n",
    "        loss = torch.sqrt(self.loss_func(torch.log1p(torch.clamp(pred, min=0.0)), torch.log1p(truth))) #RMSLE\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, loaders, optimizer, writer, num_epoch=10, device='cpu'):\n",
    "    def run_epoch(mode):\n",
    "        epoch_loss = 0.0\n",
    "        for i, batch in enumerate(loaders[mode], 0):\n",
    "            in_data, truth = batch\n",
    "            in_data, truth = in_data.to(device), truth.to(device)\n",
    "\n",
    "            if mode == 'train':\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            pred = model(in_data)\n",
    "            batch_loss = model.loss(pred, truth)\n",
    "            \n",
    "            epoch_loss += batch_loss.item()\n",
    "            if mode == 'train':\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            del in_data\n",
    "            del truth\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # sum of all batchs / num of batches\n",
    "        epoch_loss /= i + 1\n",
    "        print('epoch %d %s loss %.4f' % (epoch, mode, epoch_loss))\n",
    "        # log to tensorboard\n",
    "        if not (writer is None):\n",
    "            writer.add_scalars('%s_loss' % model.__class__.__name__,\n",
    "                         tag_scalar_dict={mode: epoch_loss}, \n",
    "                         global_step=epoch)\n",
    "    for epoch in range(num_epoch):\n",
    "        if 'train' in loaders:\n",
    "            model.train()\n",
    "            run_epoch('train')\n",
    "        if 'eval' in loaders:\n",
    "            model.eval()\n",
    "            run_epoch('eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss 5.4590\n",
      "epoch 0 eval loss 4.2746\n",
      "epoch 1 train loss 3.8986\n",
      "epoch 1 eval loss 3.6428\n",
      "epoch 2 train loss 3.5222\n",
      "epoch 2 eval loss 3.4047\n",
      "epoch 3 train loss 3.3728\n",
      "epoch 3 eval loss 3.3508\n",
      "epoch 4 train loss 3.3112\n",
      "epoch 4 eval loss 3.2802\n",
      "epoch 5 train loss 3.2986\n",
      "epoch 5 eval loss 3.2920\n",
      "epoch 6 train loss 3.2866\n",
      "epoch 6 eval loss 3.2758\n",
      "epoch 7 train loss 3.2738\n",
      "epoch 7 eval loss 3.2884\n",
      "epoch 8 train loss 3.2308\n",
      "epoch 8 eval loss 3.3078\n",
      "epoch 9 train loss 3.2883\n",
      "epoch 9 eval loss 3.2883\n",
      "epoch 10 train loss 3.2716\n",
      "epoch 10 eval loss 3.2978\n",
      "epoch 11 train loss 3.2592\n",
      "epoch 11 eval loss 3.2809\n",
      "epoch 12 train loss 3.2709\n",
      "epoch 12 eval loss 3.2773\n",
      "epoch 13 train loss 3.2353\n",
      "epoch 13 eval loss 3.2929\n",
      "epoch 14 train loss 3.2748\n",
      "epoch 14 eval loss 3.2598\n"
     ]
    }
   ],
   "source": [
    "model = Model().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2.5e-4, betas=(0.9, 0.99))\n",
    "run(\n",
    "    model=model,\n",
    "    loaders={\n",
    "        'train': torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True),\n",
    "        'eval': torch.utils.data.DataLoader(eval_data, batch_size=32, shuffle=True)\n",
    "    },\n",
    "    optimizer=optimizer, \n",
    "    writer=SummaryWriter('./logs/'), \n",
    "    num_epoch=15, \n",
    "    device='cuda'\n",
    ")\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final model over whole dataset and Export test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss 5.4525\n",
      "epoch 1 train loss 3.8975\n",
      "epoch 2 train loss 3.5295\n",
      "epoch 3 train loss 3.3565\n",
      "epoch 4 train loss 3.3179\n",
      "epoch 5 train loss 3.2972\n",
      "epoch 6 train loss 3.2817\n",
      "epoch 7 train loss 3.2904\n",
      "epoch 8 train loss 3.2773\n",
      "epoch 9 train loss 3.2905\n",
      "epoch 10 train loss 3.2752\n",
      "epoch 11 train loss 3.2703\n",
      "epoch 12 train loss 3.2880\n",
      "epoch 13 train loss 3.2594\n",
      "epoch 14 train loss 3.2652\n",
      "epoch 15 train loss 3.2842\n",
      "epoch 16 train loss 3.2726\n",
      "epoch 17 train loss 3.2807\n",
      "epoch 18 train loss 3.2529\n",
      "epoch 19 train loss 3.2527\n",
      "epoch 20 train loss 3.2655\n",
      "epoch 21 train loss 3.2736\n",
      "epoch 22 train loss 3.2644\n",
      "epoch 23 train loss 3.2514\n",
      "epoch 24 train loss 3.2642\n",
      "epoch 25 train loss 3.2517\n",
      "epoch 26 train loss 3.2497\n",
      "epoch 27 train loss 3.2296\n",
      "epoch 28 train loss 3.2638\n",
      "epoch 29 train loss 3.2322\n",
      "file saved\n"
     ]
    }
   ],
   "source": [
    "model = Model().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, betas=(0.9, 0.99))\n",
    "run(\n",
    "    model=model,\n",
    "    loaders={\n",
    "        'train': torch.utils.data.DataLoader(whole_train_data, batch_size=32, shuffle=True)\n",
    "    },\n",
    "    optimizer=optimizer, \n",
    "    writer=SummaryWriter('./logs/final/'), \n",
    "    num_epoch=30, \n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "test_pred_tensor = model(test_x.to('cuda'))\n",
    "test_pred = test_pred_tensor.detach().cpu().numpy()\n",
    "output = np.concatenate((np.expand_dims(data['test_x'][:,0], axis=1), test_pred), axis=1)\n",
    "np.savetxt('./test_out_fnn.csv', output, header='id,revenue', delimiter=',', fmt='%i', comments='')\n",
    "print('file saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
